import os
from azure.storage.blob import BlobServiceClient
import uuid
import logging
from duckduckgo_search import DDGS
from autogen_ext.code_executors.local import LocalCommandLineCodeExecutor
from autogen_ext.tools.code_execution import PythonCodeExecutionTool
import pandas as pd
from typing import List, Optional
import re
import functools
import time
import streamlit as st

logger = logging.getLogger(__name__)
logger.setLevel(logging.INFO)


def timer(func):
    """å®Ÿè¡Œæ™‚é–“ã‚’è¨ˆæ¸¬ã™ã‚‹ãƒ‡ã‚³ãƒ¬ãƒ¼ã‚¿"""

    @functools.wraps(func)
    def wrapper(*args, **kwargs):
        start_time = time.time()
        logger.info(f"{func.__name__} - é–‹å§‹")
        try:
            result = func(*args, **kwargs)
            return result
        finally:
            end_time = time.time()
            elapsed_time = end_time - start_time
            logger.info(f"{func.__name__} - å®Œäº† (å®Ÿè¡Œæ™‚é–“: {elapsed_time:.2f}ç§’)")

    return wrapper


def get_work_directory():
    """OSã«å¿œã˜ãŸä½œæ¥­ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªãƒ‘ã‚¹ã‚’å–å¾—

    Returns:
        str: ä½œæ¥­ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã®ãƒ‘ã‚¹
        - Azure App Service: '/home/site/work' (æ°¸ç¶šåŒ–ã•ã‚Œã‚‹)
        - ãƒ­ãƒ¼ã‚«ãƒ«é–‹ç™º: 'work' (ç›¸å¯¾ãƒ‘ã‚¹)

    Notes:
        Azure App Serviceã§ã¯/home/siteãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªãŒæ°¸ç¶šåŒ–ã•ã‚Œã‚‹ãŸã‚ã€
        ãã®ã‚µãƒ–ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã¨ã—ã¦workãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã‚’ä½œæˆã—ã¾ã™ã€‚
    """
    # Azure App Serviceç’°å¢ƒã®æ¤œå‡º
    # WEBSITE_SITE_NAMEç’°å¢ƒå¤‰æ•°ã¯Azure App Serviceã§ã®ã¿è¨­å®šã•ã‚Œã‚‹
    if os.getenv("WEBSITE_SITE_NAME"):
        # Azure App Serviceç’°å¢ƒï¼š/home/siteãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªå†…ã«ä½œæ¥­ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã‚’ä½œæˆ
        # /home/siteã¯æ°¸ç¶šåŒ–ã•ã‚Œã‚‹ãŸã‚å®‰å…¨
        work_dir = "/home/site/work"
        # ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªãŒå­˜åœ¨ã—ãªã„å ´åˆã¯ä½œæˆ
        try:
            os.makedirs(work_dir, exist_ok=True)
        except OSError as e:
            logger.warning(f"ä½œæ¥­ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã®ä½œæˆã«å¤±æ•—: {e}")
            # ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯: /tmpãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã‚’ä½¿ç”¨ï¼ˆä¸€æ™‚çš„ï¼‰
            work_dir = "/tmp/work"
            os.makedirs(work_dir, exist_ok=True)
        return work_dir
    else:
        # ãƒ­ãƒ¼ã‚«ãƒ«ç’°å¢ƒï¼šãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªå†…ã®ç›¸å¯¾ãƒ‘ã‚¹
        return "work"


def search_duckduckgo(query: str) -> str:
    """
    DuckDuckGoã‚’ä½¿ç”¨ã—ã¦ã‚¦ã‚§ãƒ–æ¤œç´¢ã‚’è¡Œã†ãƒ„ãƒ¼ãƒ«ã€‚

    Args:
        query (str): æ¤œç´¢ã‚¯ã‚¨ãƒªã€‚å…·ä½“çš„ãªã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ã‚„è³ªå•ã‚’å…¥åŠ›ã—ã¦ãã ã•ã„ã€‚

    Returns:
        str: æ¤œç´¢çµæœï¼ˆä¸Šä½3ä»¶ã®ã‚¿ã‚¤ãƒˆãƒ«ã¨æœ¬æ–‡ï¼‰ã€‚å„çµæœã¯æ”¹è¡Œã§åŒºåˆ‡ã‚‰ã‚Œã¾ã™ã€‚

    Examples:
        search_duckduckgo("Python machine learning")
        search_duckduckgo("2024å¹´ã®æ—¥æœ¬ã®çµŒæ¸ˆçŠ¶æ³")
    """
    try:
        print(f"[llm_agent] DuckDuckGoæ¤œç´¢ãƒ„ãƒ¼ãƒ«ã‚’ä½¿ç”¨: query='{query}'")
        with DDGS() as ddgs:
            results = ddgs.text(query)
            return "\n".join([f"{r['title']}: {r['body']}" for r in results[:3]])
    except Exception as e:
        return f"æ¤œç´¢ã‚¨ãƒ©ãƒ¼: {str(e)}"


def create_execute_tool() -> PythonCodeExecutionTool:
    """
    PythonCodeExecutionToolã‚’ä½œæˆã™ã‚‹ãƒ•ã‚¡ã‚¯ãƒˆãƒªé–¢æ•°ã€‚

    Returns:
        PythonCodeExecutionTool: è¨­å®šæ¸ˆã¿ã®Pythonã‚³ãƒ¼ãƒ‰å®Ÿè¡Œãƒ„ãƒ¼ãƒ«
    """
    return PythonCodeExecutionTool(
        LocalCommandLineCodeExecutor(
            timeout=300,
            work_dir=get_work_directory(),
            cleanup_temp_files=False,
        )
    )


def upload_image_to_blob(file_path: str) -> str:
    """
    æŒ‡å®šã•ã‚ŒãŸãƒ­ãƒ¼ã‚«ãƒ«ãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹ã®ç”»åƒã‚’Azure Blob Storageã«ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã—ã€ãã®å…¬é–‹URLã‚’è¿”ã—ã¾ã™ã€‚

    Args:
        file_path (str): ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã™ã‚‹ç”»åƒãƒ•ã‚¡ã‚¤ãƒ«ã®ãƒ­ãƒ¼ã‚«ãƒ«ãƒ‘ã‚¹

    Returns:
        str: ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰æˆåŠŸæ™‚ã¯æˆåŠŸãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã¨URLã€å¤±æ•—æ™‚ã¯ã‚¨ãƒ©ãƒ¼ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸

    Examples:
        upload_image_to_blob('C:/agent-work/my_graph.png')

    Note:
        ã‚°ãƒ©ãƒ•ã‚’ãƒ­ãƒ¼ã‚«ãƒ«ã«ä¿å­˜ã—ãŸå¾Œã«ã“ã®ãƒ„ãƒ¼ãƒ«ã‚’å‘¼ã³å‡ºã—ã¦ã€ç”»åƒã‚’ã‚¯ãƒ©ã‚¦ãƒ‰ã«ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã—ã¦ãã ã•ã„ã€‚
        ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰å¾Œã€ãƒ­ãƒ¼ã‚«ãƒ«ãƒ•ã‚¡ã‚¤ãƒ«ã¯è‡ªå‹•çš„ã«å‰Šé™¤ã•ã‚Œã¾ã™ã€‚
    """
    # ã‚³ãƒ¼ãƒ‰å®Ÿè¡Œã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã®ä½œæ¥­ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã‚’å–å¾—
    agent_work_dir = get_work_directory()
    # file_pathã‚’æ­£è¦åŒ–ã—ã€workãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªé‡è¤‡ã‚’æ’é™¤
    normalized = os.path.normpath(file_path)
    abs_work = os.path.abspath(agent_work_dir)
    # çµ¶å¯¾ãƒ‘ã‚¹ã§work_diré…ä¸‹ã‚’æŒ‡ã™å ´åˆã¯ç›¸å¯¾ãƒ‘ã‚¹ã«å¤‰æ›
    if os.path.isabs(normalized) and normalized.startswith(abs_work + os.path.sep):
        file_path = os.path.relpath(normalized, abs_work)
    else:
        # ç›¸å¯¾ãƒ‘ã‚¹ã§å…ˆé ­ã«workãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªåãŒã‚ã‚‹å ´åˆã¯å‰Šé™¤
        parts = normalized.split(os.path.sep)
        if parts and parts[0] == os.path.basename(agent_work_dir):
            file_path = os.path.sep.join(parts[1:])
        else:
            file_path = normalized

    # çµ¶å¯¾ãƒ‘ã‚¹ã§æ‰±ã†ãŸã‚ã€ä½œæ¥­ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã®çµ¶å¯¾ãƒ‘ã‚¹ã¨çµåˆ
    full_path_in_agent_work_dir = os.path.join(abs_work, file_path)

    # ã¾ãšã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã®ä½œæ¥­ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªå†…ã‚’æ¢ç´¢
    if os.path.exists(full_path_in_agent_work_dir):
        path_to_use = full_path_in_agent_work_dir
    # æ¬¡ã«æ¸¡ã•ã‚ŒãŸãƒ‘ã‚¹ã‚’ãã®ã¾ã¾æ¢ç´¢ï¼ˆå¾Œæ–¹äº’æ›æ€§ã¾ãŸã¯çµ¶å¯¾ãƒ‘ã‚¹æŒ‡å®šã®å ´åˆï¼‰
    elif os.path.exists(file_path):
        path_to_use = file_path
    else:
        return f"ã‚¨ãƒ©ãƒ¼: ãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã€‚è©¦è¡Œã—ãŸãƒ‘ã‚¹: {full_path_in_agent_work_dir} ãŠã‚ˆã³ {file_path}"

    try:
        connect_str = os.getenv("AZURE_STORAGE_CONNECTION_STRING")
        container_name = os.getenv("AZURE_STORAGE_CONTAINER_NAME")

        if not connect_str or not container_name:
            error_msg = "ç’°å¢ƒå¤‰æ•°ã«Azure Storageã®æ¥ç¶šæƒ…å ±ãŒè¨­å®šã•ã‚Œã¦ã„ã¾ã›ã‚“ã€‚"
            logger.error(error_msg)
            return f"ã‚¨ãƒ©ãƒ¼: {error_msg}"

        blob_service_client = BlobServiceClient.from_connection_string(connect_str)

        # ä¸Šæ›¸ãã‚’é˜²ããŸã‚ã«ä¸€æ„ã®BLOBåã‚’ç”Ÿæˆ
        blob_name = f"{uuid.uuid4()}-{os.path.basename(path_to_use)}"
        blob_client = blob_service_client.get_blob_client(
            container=container_name, blob=blob_name
        )

        logger.info(
            f"Uploading {path_to_use} to Azure Blob Storage as blob {blob_name}..."
        )
        with open(path_to_use, "rb") as data:
            blob_client.upload_blob(data, overwrite=True)

        logger.info("Upload successful.")
        url = blob_client.url

        # ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰å¾Œã«ãƒ­ãƒ¼ã‚«ãƒ«ãƒ•ã‚¡ã‚¤ãƒ«ã‚’å‰Šé™¤
        try:
            os.remove(path_to_use)
            logger.info(f"ãƒ­ãƒ¼ã‚«ãƒ«ãƒ•ã‚¡ã‚¤ãƒ«ã‚’å‰Šé™¤ã—ã¾ã—ãŸ: {path_to_use}")
        except Exception as e:
            logger.warning(f"ãƒ­ãƒ¼ã‚«ãƒ«ãƒ•ã‚¡ã‚¤ãƒ«ã®å‰Šé™¤ã«å¤±æ•—ã—ã¾ã—ãŸ {path_to_use}: {e}")

        return f"ç”»åƒã®ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã«æˆåŠŸã—ã¾ã—ãŸã€‚[image: {url}]"

    except Exception as e:
        logger.error(f"Azure Blob Storageã¸ã®ãƒ•ã‚¡ã‚¤ãƒ«ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã«å¤±æ•—ã—ã¾ã—ãŸ: {e}")
        return f"ã‚¨ãƒ©ãƒ¼: ãƒ•ã‚¡ã‚¤ãƒ«ã®ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã«å¤±æ•—ã—ã¾ã—ãŸã€‚ {e}"


def load_erp_data(year_months: List[str] = None, skus: List[str] = None) -> str:
    """
    SKUã®å›ºå®šè²»ã¨å¤‰å‹•è²»ã‚’èª­ã¿è¾¼ã¿ã€æŒ‡å®šã•ã‚ŒãŸå¹´æœˆã¨SKUã«åŸºã¥ã„ã¦CSVãƒ‡ãƒ¼ã‚¿ã‚’è¿”ã™ãƒ„ãƒ¼ãƒ«ã€‚

    Args:
        year_months (List[str], optional): ãƒ•ã‚£ãƒ«ã‚¿ã™ã‚‹å¹´æœˆã®ãƒªã‚¹ãƒˆï¼ˆä¾‹: ["2023-01", "2023-02"]ï¼‰
        skus (List[str], optional): ãƒ•ã‚£ãƒ«ã‚¿ã™ã‚‹SKUã®ãƒªã‚¹ãƒˆï¼ˆä¾‹: ["SKU001", "SKU002"]ï¼‰

    Returns:
        str: æŒ‡å®šã•ã‚ŒãŸå¹´æœˆã¨SKUã«åŸºã¥ã„ãŸCSVãƒ‡ãƒ¼ã‚¿

    Examples:
        load_erp_data(["2023-01"], ["SKU001", "SKU002"])
        load_erp_data(year_months=["2023-01", "2023-02"])
        load_erp_data(skus=["SKU001"])
        load_erp_data()  # å…¨ãƒ‡ãƒ¼ã‚¿ã‚’å–å¾—
    """
    try:
        # ERPãƒ•ã‚¡ã‚¤ãƒ«ã®ãƒ‘ã‚¹ã‚’è¨­å®š
        erp_file_path = os.path.join(
            os.path.dirname(os.path.dirname(os.path.dirname(__file__))),
            "sampledata",
            "erp.csv",
        )

        if not os.path.exists(erp_file_path):
            return f"ã‚¨ãƒ©ãƒ¼: ERPãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: {erp_file_path}"

        # CSVãƒ•ã‚¡ã‚¤ãƒ«ã‚’èª­ã¿è¾¼ã¿
        df = pd.read_csv(erp_file_path, encoding="utf-8")
        # å¹´æœˆã§ãƒ•ã‚£ãƒ«ã‚¿
        if year_months:
            df = df[df["å¹´æœˆ"].isin(year_months)]

        # SKUã§ãƒ•ã‚£ãƒ«ã‚¿
        if skus:
            df = df[df["SKU"].isin(skus)]
        # CSVã®å†…å®¹ã‚’æ–‡å­—åˆ—ã¨ã—ã¦è¿”ã™
        csv_content = df.to_csv(index=True, encoding="utf-8")

        return csv_content

    except Exception as e:
        logger.error(f"ERPãƒ‡ãƒ¼ã‚¿ã®èª­ã¿è¾¼ã¿ã‚¨ãƒ©ãƒ¼: {str(e)}")
        return f"ã‚¨ãƒ©ãƒ¼: ERPãƒ‡ãƒ¼ã‚¿ã®èª­ã¿è¾¼ã¿ã«å¤±æ•—ã—ã¾ã—ãŸ: {str(e)}"


def load_material_cost_breakdown(year_months: List[str], sku: str) -> str:
    """
    SKUã®ææ–™è²»ã®å†…è¨³ãƒ‡ãƒ¼ã‚¿ã‚’èª­ã¿è¾¼ã¿ã€æŒ‡å®šã•ã‚ŒãŸå¹´æœˆã¨SKUã«åŸºã¥ã„ã¦åŸæ–™åˆ¥ã®è²»ç”¨å†…è¨³ã‚’è¿”ã™ãƒ„ãƒ¼ãƒ«ã€‚

    Args:
        year_months (List[str]): ãƒ•ã‚£ãƒ«ã‚¿ã™ã‚‹å¹´æœˆã®ãƒªã‚¹ãƒˆï¼ˆä¾‹: ["2023-01", "2023-02"]ï¼‰
        sku (str): ãƒ•ã‚£ãƒ«ã‚¿ã™ã‚‹SKUï¼ˆä¾‹: "SKU001"ï¼‰

    Returns:
        str: æŒ‡å®šã•ã‚ŒãŸå¹´æœˆã¨SKUã«åŸºã¥ã„ãŸææ–™è²»å†…è¨³ã®CSVãƒ‡ãƒ¼ã‚¿

    Examples:
        load_material_cost_breakdown(["2023-01", "2023-02"], "SKU001")
        load_material_cost_breakdown(["2024-01"], "SKU001")
    """
    try:
        # ææ–™è²»ãƒ•ã‚¡ã‚¤ãƒ«ã®ãƒ‘ã‚¹ã‚’è¨­å®š
        material_file_path = os.path.join(
            os.path.dirname(os.path.dirname(os.path.dirname(__file__))),
            "sampledata",
            "erp_material.csv",
        )

        if not os.path.exists(material_file_path):
            return f"ã‚¨ãƒ©ãƒ¼: ææ–™è²»ãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: {material_file_path}"

        # CSVãƒ•ã‚¡ã‚¤ãƒ«ã‚’èª­ã¿è¾¼ã¿
        df = pd.read_csv(material_file_path, encoding="utf-8")

        # å¹´æœˆã§ãƒ•ã‚£ãƒ«ã‚¿
        if year_months:
            df = df[df["å¹´æœˆ"].isin(year_months)]

        # SKUã§ãƒ•ã‚£ãƒ«ã‚¿
        if sku:
            df = df[df["SKU"] == sku]

        if df.empty:
            return f"æŒ‡å®šã•ã‚ŒãŸæ¡ä»¶ï¼ˆå¹´æœˆ: {year_months}, SKU: {sku}ï¼‰ã«è©²å½“ã™ã‚‹ãƒ‡ãƒ¼ã‚¿ãŒã‚ã‚Šã¾ã›ã‚“ã€‚"

        # CSVã®å†…å®¹ã‚’æ–‡å­—åˆ—ã¨ã—ã¦è¿”ã™
        csv_content = df.to_csv(index=False, encoding="utf-8")

        return csv_content

    except Exception as e:
        logger.error(f"ææ–™è²»ãƒ‡ãƒ¼ã‚¿ã®èª­ã¿è¾¼ã¿ã‚¨ãƒ©ãƒ¼: {str(e)}")
        return f"ã‚¨ãƒ©ãƒ¼: ææ–™è²»ãƒ‡ãƒ¼ã‚¿ã®èª­ã¿è¾¼ã¿ã«å¤±æ•—ã—ã¾ã—ãŸ: {str(e)}"


def load_mes_total_data(year_months: List[str] = None, skus: List[str] = None) -> str:
    """
    MESç·åˆãƒ‡ãƒ¼ã‚¿ï¼ˆè‰¯å“æ•°ãƒ»ä¸è‰¯æ•°ï¼‰ã‚’èª­ã¿è¾¼ã¿ã€æŒ‡å®šã•ã‚ŒãŸå¹´æœˆã¨SKUã«åŸºã¥ã„ã¦CSVãƒ‡ãƒ¼ã‚¿ã‚’è¿”ã™ãƒ„ãƒ¼ãƒ«ã€‚

    Args:
        year_months (List[str], optional): ãƒ•ã‚£ãƒ«ã‚¿ã™ã‚‹å¹´æœˆã®ãƒªã‚¹ãƒˆï¼ˆä¾‹: ["2024-06", "2024-07"]ï¼‰
        skus (List[str], optional): ãƒ•ã‚£ãƒ«ã‚¿ã™ã‚‹SKUã®ãƒªã‚¹ãƒˆï¼ˆä¾‹: ["SKU001", "SKU002"]ï¼‰

    Returns:
        str: æŒ‡å®šã•ã‚ŒãŸå¹´æœˆã¨SKUã«åŸºã¥ã„ãŸè‰¯å“æ•°ãƒ»ä¸è‰¯æ•°ã®CSVãƒ‡ãƒ¼ã‚¿

    Examples:
        load_mes_total_data(["2024-06"], ["SKU001", "SKU002"])
        load_mes_total_data(year_months=["2024-06", "2024-07"])
        load_mes_total_data(skus=["SKU001"])
        load_mes_total_data()  # å…¨ãƒ‡ãƒ¼ã‚¿ã‚’å–å¾—
    """
    try:
        # MESç·åˆãƒ‡ãƒ¼ã‚¿ãƒ•ã‚¡ã‚¤ãƒ«ã®ãƒ‘ã‚¹ã‚’è¨­å®š
        mes_total_file_path = os.path.join(
            os.path.dirname(os.path.dirname(os.path.dirname(__file__))),
            "sampledata",
            "mes_total.csv",
        )

        if not os.path.exists(mes_total_file_path):
            return (
                f"ã‚¨ãƒ©ãƒ¼: MESç·åˆãƒ‡ãƒ¼ã‚¿ãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: {mes_total_file_path}"
            )

        # CSVãƒ•ã‚¡ã‚¤ãƒ«ã‚’èª­ã¿è¾¼ã¿
        df = pd.read_csv(mes_total_file_path, encoding="utf-8")

        # å¹´æœˆã§ãƒ•ã‚£ãƒ«ã‚¿ï¼ˆå¹´æœˆæ—¥ã‹ã‚‰å¹´æœˆã‚’æŠ½å‡ºã—ã¦ãƒ•ã‚£ãƒ«ã‚¿ï¼‰
        if year_months:
            df["å¹´æœˆ"] = df["å¹´æœˆæ—¥"].str[:7]  # YYYY-MM-DD ã‹ã‚‰ YYYY-MM ã‚’æŠ½å‡º
            df = df[df["å¹´æœˆ"].isin(year_months)]
            df = df.drop(columns=["å¹´æœˆ"])  # ä¸€æ™‚çš„ã«è¿½åŠ ã—ãŸå¹´æœˆã‚«ãƒ©ãƒ ã‚’å‰Šé™¤

        # SKUã§ãƒ•ã‚£ãƒ«ã‚¿
        if skus:
            df = df[df["SKU"].isin(skus)]

        if df.empty:
            return f"æŒ‡å®šã•ã‚ŒãŸæ¡ä»¶ï¼ˆå¹´æœˆ: {year_months}, SKU: {skus}ï¼‰ã«è©²å½“ã™ã‚‹ãƒ‡ãƒ¼ã‚¿ãŒã‚ã‚Šã¾ã›ã‚“ã€‚"

        # CSVã®å†…å®¹ã‚’æ–‡å­—åˆ—ã¨ã—ã¦è¿”ã™
        csv_content = df.to_csv(index=False, encoding="utf-8")

        return csv_content

    except Exception as e:
        logger.error(f"MESç·åˆãƒ‡ãƒ¼ã‚¿ã®èª­ã¿è¾¼ã¿ã‚¨ãƒ©ãƒ¼: {str(e)}")
        return f"ã‚¨ãƒ©ãƒ¼: MESç·åˆãƒ‡ãƒ¼ã‚¿ã®èª­ã¿è¾¼ã¿ã«å¤±æ•—ã—ã¾ã—ãŸ: {str(e)}"


def load_mes_loss_data(year_months: List[str] = None, skus: List[str] = None) -> str:
    """
    MESãƒ­ã‚¹å†…è¨³ãƒ‡ãƒ¼ã‚¿ï¼ˆåŠ å·¥æ©Ÿãƒ­ã‚¹ã€åŒ…è£…æ©Ÿãƒ­ã‚¹ã€æ¤œå“ãƒ­ã‚¹ã€ãƒ•ã‚£ãƒ«ãƒ ãƒ­ã‚¹ã€ä¸æ˜ãƒ­ã‚¹ï¼‰ã‚’èª­ã¿è¾¼ã¿ã€
    æŒ‡å®šã•ã‚ŒãŸå¹´æœˆã¨SKUã«åŸºã¥ã„ã¦CSVãƒ‡ãƒ¼ã‚¿ã‚’è¿”ã™ãƒ„ãƒ¼ãƒ«ã€‚

    Args:
        year_months (List[str], optional): ãƒ•ã‚£ãƒ«ã‚¿ã™ã‚‹å¹´æœˆã®ãƒªã‚¹ãƒˆï¼ˆä¾‹: ["2024-06", "2024-07"]ï¼‰
        skus (List[str], optional): ãƒ•ã‚£ãƒ«ã‚¿ã™ã‚‹SKUã®ãƒªã‚¹ãƒˆï¼ˆä¾‹: ["SKU001", "SKU002"]ï¼‰

    Returns:
        str: æŒ‡å®šã•ã‚ŒãŸå¹´æœˆã¨SKUã«åŸºã¥ã„ãŸãƒ­ã‚¹å†…è¨³ã®CSVãƒ‡ãƒ¼ã‚¿

    Examples:
        load_mes_loss_data(["2024-06"], ["SKU001", "SKU002"])
        load_mes_loss_data(year_months=["2024-06", "2024-07"])
        load_mes_loss_data(skus=["SKU001"])
        load_mes_loss_data()  # å…¨ãƒ‡ãƒ¼ã‚¿ã‚’å–å¾—
    """
    try:
        # MESãƒ­ã‚¹å†…è¨³ãƒ‡ãƒ¼ã‚¿ãƒ•ã‚¡ã‚¤ãƒ«ã®ãƒ‘ã‚¹ã‚’è¨­å®š
        mes_loss_file_path = os.path.join(
            os.path.dirname(os.path.dirname(os.path.dirname(__file__))),
            "sampledata",
            "mes_total_err.csv",
        )

        if not os.path.exists(mes_loss_file_path):
            return f"ã‚¨ãƒ©ãƒ¼: MESãƒ­ã‚¹å†…è¨³ãƒ‡ãƒ¼ã‚¿ãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: {mes_loss_file_path}"

        # CSVãƒ•ã‚¡ã‚¤ãƒ«ã‚’èª­ã¿è¾¼ã¿
        df = pd.read_csv(mes_loss_file_path, encoding="utf-8")

        # å¹´æœˆã§ãƒ•ã‚£ãƒ«ã‚¿ï¼ˆå¹´æœˆæ—¥ã‹ã‚‰å¹´æœˆã‚’æŠ½å‡ºã—ã¦ãƒ•ã‚£ãƒ«ã‚¿ï¼‰
        if year_months:
            df["å¹´æœˆ"] = df["å¹´æœˆæ—¥"].str[:7]  # YYYY-MM-DD ã‹ã‚‰ YYYY-MM ã‚’æŠ½å‡º
            df = df[df["å¹´æœˆ"].isin(year_months)]
            df = df.drop(columns=["å¹´æœˆ"])  # ä¸€æ™‚çš„ã«è¿½åŠ ã—ãŸå¹´æœˆã‚«ãƒ©ãƒ ã‚’å‰Šé™¤

        # SKUã§ãƒ•ã‚£ãƒ«ã‚¿
        if skus:
            df = df[df["SKU"].isin(skus)]

        if df.empty:
            return f"æŒ‡å®šã•ã‚ŒãŸæ¡ä»¶ï¼ˆå¹´æœˆ: {year_months}, SKU: {skus}ï¼‰ã«è©²å½“ã™ã‚‹ãƒ‡ãƒ¼ã‚¿ãŒã‚ã‚Šã¾ã›ã‚“ã€‚"

        # CSVã®å†…å®¹ã‚’æ–‡å­—åˆ—ã¨ã—ã¦è¿”ã™
        csv_content = df.to_csv(index=False, encoding="utf-8")

        return csv_content

    except Exception as e:
        logger.error(f"MESãƒ­ã‚¹å†…è¨³ãƒ‡ãƒ¼ã‚¿ã®èª­ã¿è¾¼ã¿ã‚¨ãƒ©ãƒ¼: {str(e)}")
        return f"ã‚¨ãƒ©ãƒ¼: MESãƒ­ã‚¹å†…è¨³ãƒ‡ãƒ¼ã‚¿ã®èª­ã¿è¾¼ã¿ã«å¤±æ•—ã—ã¾ã—ãŸ: {str(e)}"


def load_daily_report(month: str, keyword: Optional[str] = None) -> str:
    """
    æ—¥å ±ãƒ‡ãƒ¼ã‚¿ï¼ˆdaily_report.csvï¼‰ã‚’èª­ã¿è¾¼ã¿ã€æŒ‡å®šã•ã‚ŒãŸæœˆã¨ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ã§æ¤œç´¢ã™ã‚‹ãƒ„ãƒ¼ãƒ«ã€‚

    Args:
        month (str): ãƒ•ã‚£ãƒ«ã‚¿ã™ã‚‹å¹´æœˆï¼ˆä¾‹: "2024-07"ï¼‰ã€‚
        keyword (Optional[str], optional): æ¤œç´¢ã™ã‚‹ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ã€‚'å†…å®¹'åˆ—ã‹ã‚‰éƒ¨åˆ†ä¸€è‡´ã§æ¤œç´¢ã—ã¾ã™ã€‚æŒ‡å®šã—ãªã„å ´åˆã¯ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ã§ã®çµã‚Šè¾¼ã¿ã¯è¡Œã„ã¾ã›ã‚“ã€‚

    Returns:
        str: æ¤œç´¢çµæœã®CSVãƒ‡ãƒ¼ã‚¿ã€‚

    Examples:
        load_daily_report(month="2024-07", keyword="ãƒˆãƒ©ãƒ–ãƒ«")
        load_daily_report(month="2024-06")
    """
    try:
        # daily_report.csvã®ãƒ‘ã‚¹ã‚’è¨­å®š
        report_file_path = os.path.join(
            os.path.dirname(os.path.dirname(os.path.dirname(__file__))),
            "sampledata",
            "daily_report.csv",
        )

        if not os.path.exists(report_file_path):
            return f"ã‚¨ãƒ©ãƒ¼: æ—¥å ±ãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: {report_file_path}"

        # CSVãƒ•ã‚¡ã‚¤ãƒ«ã‚’èª­ã¿è¾¼ã¿
        df = pd.read_csv(report_file_path, encoding="utf-8")

        # 'å¹´æœˆæ—¥'åˆ—ã‚’datetimeå‹ã«å¤‰æ›ã—ã€å¹´æœˆã§ãƒ•ã‚£ãƒ«ã‚¿
        df["å¹´æœˆæ—¥"] = pd.to_datetime(df["å¹´æœˆæ—¥"])
        df_filtered = df[df["å¹´æœˆæ—¥"].dt.strftime("%Y-%m") == month]
        logger.info(
            f"ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°å¾Œã®ãƒ‡ãƒ¼ã‚¿è¡Œæ•°: {len(df_filtered)} (æœˆ: {month}, ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰: {keyword})"
        )

        # ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ã§ãƒ•ã‚£ãƒ«ã‚¿ï¼ˆ'å†…å®¹'åˆ—ã‚’æƒ³å®šï¼‰
        if keyword and "å†…å®¹" in df_filtered.columns:
            df_filtered = df_filtered[
                df_filtered["å†…å®¹"].str.contains(keyword, na=False)
            ]

        if df_filtered.empty:
            return f"æŒ‡å®šã•ã‚ŒãŸæ¡ä»¶ï¼ˆå¹´æœˆ: {month}, ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰: {keyword}ï¼‰ã«è©²å½“ã™ã‚‹ãƒ‡ãƒ¼ã‚¿ãŒã‚ã‚Šã¾ã›ã‚“ã€‚"

        # CSVã®å†…å®¹ã‚’æ–‡å­—åˆ—ã¨ã—ã¦è¿”ã™
        csv_content = df_filtered.to_csv(index=False, encoding="utf-8")

        return csv_content

    except Exception as e:
        import traceback

        logger.error(f"æ—¥å ±ãƒ‡ãƒ¼ã‚¿ã®èª­ã¿è¾¼ã¿ã‚¨ãƒ©ãƒ¼: {str(e)}")
        logger.error(f"ã‚¨ãƒ©ãƒ¼ã®è©³ç´°: {traceback.format_exc()}")
        return f"ã‚¨ãƒ©ãƒ¼: æ—¥å ±ãƒ‡ãƒ¼ã‚¿ã®èª­ã¿è¾¼ã¿ã«å¤±æ•—ã—ã¾ã—ãŸ: {str(e)}"


def check_content(input_str: str) -> str:
    """
    å…¥åŠ›æ–‡å­—åˆ—ãŒFunction***ã‹ã©ã†ã‹åˆ¤å®šã™ã‚‹

    Args:
        input_str (str): ãƒã‚§ãƒƒã‚¯ã™ã‚‹æ–‡å­—åˆ—

    Returns:
        str: å…¥åŠ›ãŒFunction***ã®å ´åˆã¯ãƒ‘ãƒ¼ã‚¹ã—ã¦nameå±æ€§ã‚’å–ã‚Šå‡ºã™
    """
    try:
        # ãƒ‘ã‚¿ãƒ¼ãƒ³1: FunctionExecutionResultï¼ˆcontentãƒ™ãƒ¼ã‚¹ï¼‰ - ãƒªã‚¹ãƒˆå½¢å¼
        content_pattern = r"FunctionExecutionResult\(.*?name=['\"]([^'\"]+)['\"].*?\)"
        content_matches = re.findall(content_pattern, input_str)

        if content_matches:
            name_value = content_matches[0]
            logger.info(f"name (contentå½¢å¼): {name_value}")
            return name_value
        # æ­£è¦è¡¨ç¾ãƒ‘ã‚¿ãƒ¼ãƒ³ï¼šname ã‚’æŠ½å‡º
        function_call_pattern = r"FunctionCall\(.*?name='([^']*)'.*?\)"
        function_call_matches = re.findall(function_call_pattern, input_str)

        # çµæœã‚’ãƒªã‚¹ãƒˆã«æ ¼ç´
        for name_value in function_call_matches:
            logger.info(f"name: {name_value}")
            return name_value
    except Exception as e:
        logger.error(f"check_contentã®ã‚¨ãƒ©ãƒ¼: {str(e)}")
        return None
    return None


def display_multiagent_chat_message(message, index):
    """
    ãƒãƒ«ãƒã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã®ãƒãƒ£ãƒƒãƒˆãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚’è¡¨ç¤ºã™ã‚‹é–¢æ•°ã€‚

    Args:
        message (TextMessage): è¡¨ç¤ºã™ã‚‹ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆã€‚
        index (int): ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã®ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ã€‚
    """
    role = "ğŸ¤– ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆ" if message.source != "user" else "ğŸ‘¤ ãƒ¦ãƒ¼ã‚¶ãƒ¼"
    st.markdown(f"**{role} ({index + 1}):**")
    st.markdown(f"> {message.content}")
